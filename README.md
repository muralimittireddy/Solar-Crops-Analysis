# Solar-Crops-Analysis
**Solar-Crops-Analysis** is an end-to-end Data Engineering and Machine Learning pipeline that leverages weather data to explore the impact of solar energy on agriculture. The project demonstrates complete lifecycle implementation â€” from data ingestion, transformation, and modeling to dashboarding â€” all containerized and deployed on a Google Cloud Platform Virtual Machine.

## ðŸ› ï¸ End-to-End Pipeline Overview

- ðŸ”„ Fetch weather data from Open-Meteo API
- â˜ï¸ Store raw data in **Google Cloud Storage (Parquet)** and **PostgreSQL**
- ðŸ”§ Transform data using **Apache Spark**
- ðŸš€ Load transformed data into **BigQuery**
- ðŸ§  Train a **Random Forest Machine Learning model** using data from BigQuery
- ðŸ“ˆ Build **Grafana dashboards** for visual insights
- ðŸ§© Orchestrate tasks using **Apache Airflow**
- ðŸ“¦ Containerized using **Docker**
- ðŸŒ Fully deployed and executed in a **GCP Virtual Machine**

## Project Architecture

Hereâ€™s an overview of the project architecture:

![Project Architecture](images/architecture.png)

## ðŸ› ï¸ Installation Guide

This guide provides step-by-step instructions to set up and run the Solar Crops Analysis project on a Google Cloud Platform (GCP) Virtual Machine.

---

### âœ… Step 1: Pre-requisites & GCP Setup

#### ðŸ” 1.1 Create a Service Account

Before creating the VM:

1. Go to **IAM & Admin > Service Accounts** in the GCP Console.
2. Create a new service account and assign the following roles:
  BigQuery Admin,
  BigQuery Data Editor,
  BigQuery Job User,
  BigQuery Read Session User,
  Editor,
  Storage Admin,
  Storage Object Creator,
  Storage Object Viewer
3. While creating the VM (in the next step), **attach this service account** to the instance.
---
### ðŸŒ Step 2: Configure Firewall Rules

Create firewall rules to allow external access to essential services:

| Port | Purpose            |
|------|--------------------|
| 8080 | Apache Airflow UI  |
| 3000 | Grafana Dashboards |

Set up these rules under **VPC Network > Firewall** with **Ingress** direction.

---

### ðŸ–¥ï¸ Step 3: Create a VM Instance

1. Go to **Compute Engine > VM Instances** and click **Create Instance**.
2. Recommended configuration:
- **Name**: `solar-crops-vm`
- **Machine Type**: `e2-standard-2` or higher
- **Boot Disk**: Ubuntu 20.04 LTS
- **Firewall**: Allow HTTP and HTTPS traffic
- **Service Account**: Attach the one created earlier

---
### ðŸ”‘ Step 4: Generate and Configure SSH Keys

#### 4.1 On Local Machine

    cd ~/.ssh

    ssh-keygen -t rsa -f solar_key -C your_username

This will generate:

solar_key â†’ Private Key

solar_key.pub â†’ Public Key

#### 4.2 Add Public Key to VM Metadata

Go to Compute Engine > Metadata > SSH Keys and paste the contents of solar_key.pub.

#### 4.3 Connect to the VM

Option 1: Direct command

    ssh -i ~/.ssh/solar_key your_username@<EXTERNAL_IP>

Option 2: SSH config (recommended)

Create a config file ~/.ssh/config:

    Host solar-vm

      HostName <EXTERNAL_IP>
      
      User your_username
      
      IdentityFile ~/.ssh/solar_key
    
Then connect with:

    cd .ssh
    ssh solar-vm

---
### ðŸ³ Step 5: Install Docker & Docker Compose

#### 5.1 Install Docker

    sudo apt update

    sudo apt install -y docker.io

After installing  to run docker without sudo commands, follow the below github repo

https://github.com/sindresorhus/guides/blob/main/docker-without-sudo.md

#### 5.2 Install Docker Compose

    mkdir bin
    cd bin
    curl -L "https://github.com/docker/compose/releases/download/v2.35.0/docker-compose-linux-x86_64" -o docker-compose
    chmod +x docker-compose
    echo 'export PATH=${HOME}/bin:${PATH}' >> ~/.bashrc
    source ~/.bashrc
    
Verify installation:

    docker --version
    docker-compose --version

---

### ðŸ“¦ Step 6: Clone the Project Repository

Clone the GitHub repository into your VM:

    git clone https://github.com/muralimittireddy/Solar-Crops-Analysis.git
    cd Solar-Crops-Analysis

---

### ðŸš€ Step 7: Run the Project Using Docker Compose

Make sure you're inside the project directory:

    docker-compose up --build
---

### ðŸ“Š  Step 8: Access the Services

Once the containers are up and running, open your browser and access:

 _________________________________________________________________
 
| Service	   |                    URL                              |

| Airflow UI | [Apache Airflow UI] (http://<EXTERNAL_IP>:8080)     |

| Grafana    | [Grafana Dashboards] (http://<EXTERNAL_IP>:3000)    |

 Replace <EXTERNAL_IP> with your GCP VMâ€™s public IP.
